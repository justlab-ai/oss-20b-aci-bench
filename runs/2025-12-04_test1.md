# Evaluation Run: 2025-12-04

## Configuration

| Parameter | Value |
|-----------|-------|
| Date | 2025-12-04 |
| Dataset | ACI-Bench |
| Split | test1 |
| Samples | 40 |
| Infrastructure | AWS Bedrock (us-east-1) |
| Temperature | 0.3 |
| Max Tokens | 1024 |
| Approach | Zero-shot, full-note generation |

## Models Evaluated

| Model | Model ID | Parameters |
|-------|----------|------------|
| gpt-oss-20b | openai.gpt-oss-20b-1:0 | 20B |
| gpt-oss-120b | openai.gpt-oss-120b-1:0 | 120B |

## Results

### Summary

| Model | ROUGE-1 | ROUGE-2 | ROUGE-L | Samples | Avg Inference |
|-------|---------|---------|---------|---------|---------------|
| gpt-oss-20b | 43.84 | 14.73 | 20.08 | 39/40 | ~28s |
| gpt-oss-120b | 44.35 | 14.71 | 19.43 | 40/40 | ~6s |

### Comparison with Published Benchmarks

| Model | Type | ROUGE-1 | ROUGE-2 | ROUGE-L | Source |
|-------|------|---------|---------|---------|--------|
| BART+FT SAMSum Division | Fine-tuned | 53.46 | 25.08 | 48.62 | Yim et al. 2023 |
| GPT-4 | Proprietary | 51.76 | 22.58 | 45.97 | Yim et al. 2023 |
| BART Division | Fine-tuned | 51.56 | 24.06 | 45.92 | Yim et al. 2023 |
| ChatGPT | Proprietary | 47.44 | 19.01 | 42.47 | Yim et al. 2023 |
| Text-Davinci-003 | Proprietary | 47.07 | 22.08 | 43.11 | Yim et al. 2023 |
| **gpt-oss-120b** | **Open Source** | **44.35** | **14.71** | **19.43** | This run |
| **gpt-oss-20b** | **Open Source** | **43.84** | **14.73** | **20.08** | This run |
| Text-Davinci-002 | Proprietary | 41.08 | 17.27 | 37.46 | Yim et al. 2023 |

### Gap Analysis (vs GPT-4)

| Model | ROUGE-1 Gap | ROUGE-2 Gap | ROUGE-L Gap |
|-------|-------------|-------------|-------------|
| gpt-oss-20b | -7.92 pts | -7.85 pts | -25.89 pts |
| gpt-oss-120b | -7.41 pts | -7.87 pts | -26.54 pts |

## Observations

1. **ROUGE-1/2**: OSS models perform between Text-Davinci-002 and ChatGPT
2. **ROUGE-L**: Significant gap (~25 pts) suggests structural differences in note generation
3. **20B vs 120B**: Marginal difference (~0.5 pts), 120B slightly better on ROUGE-1
4. **Inference**: 120B faster than 20B due to infrastructure optimizations
5. **Failures**: 1 timeout on gpt-oss-20b (sample 33)

## Notes

- Test1 split corresponds to MEDIQA-CHAT Task B test set
- Published benchmarks from Yim et al. 2023 (Nature Scientific Data)
- All scores reported as F1 percentages
